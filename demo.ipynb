{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panka\\OneDrive\\Desktop\\Ai Agent projects\\Agentic_RAG\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "c:\\Users\\panka\\OneDrive\\Desktop\\Ai Agent projects\\Agentic_RAG\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:502: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "c:\\Users\\panka\\OneDrive\\Desktop\\Ai Agent projects\\Agentic_RAG\\.venv\\Lib\\site-packages\\crewai_tools\\tools\\scrapegraph_scrape_tool\\scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "c:\\Users\\panka\\OneDrive\\Desktop\\Ai Agent projects\\Agentic_RAG\\.venv\\Lib\\site-packages\\crewai_tools\\tools\\selenium_scraping_tool\\selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "c:\\Users\\panka\\OneDrive\\Desktop\\Ai Agent projects\\Agentic_RAG\\.venv\\Lib\\site-packages\\crewai_tools\\tools\\vision_tool\\vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"image_path_url\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from crewai_tools import PDFSearchTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from crewai.tools import tool\n",
    "from crewai import Crew\n",
    "from crewai import Task\n",
    "from crewai import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAwMqy6yqO0czghcmiljDOw-cgrTELItEM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(\n",
    "#     openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "#     openai_api_key=os.environ['GROQ_API_KEY'],\n",
    "#     model_name=\"llama3-8b-8192\",\n",
    "#     temperature=0.1,\n",
    "#     max_tokens=1000,\n",
    "# )\n",
    "\n",
    "gemini_api_key=\"AIzaSyAwMqy6yqO0czghcmiljDOw-cgrTELItEM\"\n",
    "\n",
    "from crewai.llm import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",temperature=0.3,api_key=gemini_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mWhere is india\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LLM' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "llm.run(\"Where is india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "pdf_url = \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "with open(\"attenstion_is_all_you_need.pdf\", \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_tool = PDFSearchTool(pdf='attenstion_is_all_you_need.pdf',\n",
    "    config=dict(\n",
    "        llm=dict(\n",
    "            provider=\"google\", # or google, openai, anthropic, llama2, ...\n",
    "            config=dict(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                # temperature=0.5,\n",
    "                # top_p=1,\n",
    "                # stream=true,\n",
    "            ),\n",
    "        ),\n",
    "        embedder=dict(\n",
    "            provider=\"huggingface\", # or openai, ollama, ...\n",
    "            config=dict(\n",
    "                model=\"BAAI/bge-small-en-v1.5\",\n",
    "                #task_type=\"retrieval_document\",\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Search a PDF's content\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Relevant Content:\\nmakes it more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2. Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 22, 23, 19]. End-to-end memory networks are based on a recurrent attention mechanism instead of sequence- aligned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks [28]. To the best of our knowledge, however, the Transformer is\\n\\nmemory replace attention? In Advances in Neural Information Processing Systems, (NIPS), 2016. 10\\n\\nAttention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser ∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_tool.run(\"How did self-attention mechanism evolve in large language models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the Tavily API key\n",
    "os.environ['TAVILY_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://medium.com/data-science-community-srm/exploring-attention-mechanisms-in-large-language-models-33549ae2c5b8',\n",
       "  'content': 'Exploring Attention Mechanisms in Large Language Models | by Aryan Raj | DataX Journal | Medium Digging Deeper and Understanding How Large Language Models Pay Attention to Words for Better Performance. It’s like when you read a sentence, and you give more attention to certain words based on what came before. In the Transformer architecture, the self-attention mechanism plays a crucial role by helping the model decide how important each word or token is in a sequence. This attention layer is like a guide for the model, helping it understand words better. Attention mechanisms allow the model to focus on specific parts of the input sequence, enabling it to understand relationships between words, capture context, and generate more accurate and contextually relevant outputs.'},\n",
       " {'url': 'https://medium.com/@vimal.parakhiya/decoding-large-language-models-a-deep-dive-into-the-self-attention-mechanism-967d6207d4ae',\n",
       "  'content': 'Decoding Large Language Models: A Deep Dive into the Self-Attention Mechanism | by Vimal Parakhiya | Medium Decoding Large Language Models: A Deep Dive into the Self-Attention Mechanism This post dives deeper into the mechanics of self-attention to decode how LLM discerns the intricate relationships between words, shown in the example below. The self-attention mechanism then maps Queries to Keys to understand word relationships. This methodology is then applied to every word in the sentence (input text), adeptly discerning the contextual relationships and nuances of each term. It’s important to note that, unlike our sequential way of reading English sentences from left to right, the LLM uses self-attention to establish relationships between all words in an input text simultaneously.'},\n",
       " {'url': 'https://www.ibm.com/think/topics/what-is-self-attention',\n",
       "  'content': 'Using self-attention, LLM training data can be split into batches and processed concurrently on multiple GPUs.1 Self-attention reduces the computational power needed to train machine learning models with efficient batching processed in parallel. Self-attention in machine learning models is similar to the human behavioral concept in that they both involve focusing on relevant elements within a larger context to accurately process information. An input sequence is a series of data points vectorized into embeddings, or numerical representations, that the machine learning algorithm can use to calculate attention scores needed to produce an output sequence. AI models use self-attention\\xa0to process long input sequences efficiently, exchanging attention information at scale while reducing memory usage.5 Self-attention allows the model to gain a deeper contextual understanding by using the context window within the model.'},\n",
       " {'url': 'https://www.linkedin.com/pulse/what-self-attention-impact-large-language-models-llm-nikhil-goel-srpbc',\n",
       "  'content': \"What is Self-Attention and impact on Large Language Models (LLM) By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy. By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy. By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy. [Skip to main content](https://www.linkedin.com/pulse/what-self-attention-impact-large-language-models-llm-nikhil-goel-srpbc#main-content) Self-Attention and impact on Large Language Models What is Self-Attention and impact on Large Language Models (LLM) In today's article I am going to cover in detail about the Self Attention mechanism and the impact on LLM's. Let's dive into how Self-Attention is used in Large Language Models.\"},\n",
       " {'url': 'https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention',\n",
       "  'content': 'In other words, the self-attention mechanism enables the model to weigh the importance of different elements in an input sequence and dynamically adjust their influence on the output. Before we begin, let\\'s consider an input sentence \"Life is short, eat dessert first\" that we want to put through the self-attention mechanism. Finally, the last step is to compute the context vector z(2), which is an attention-weighted version of our original query input x(2), including all the other input elements as its context via the attention weights: Following PyTorch conventions, the SelfAttention class above initializes the self-attention parameters in the __init__ method and computes attention weights and context vectors for all inputs via the forward method.'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search_tool.run(\"What is self-attention mechansim in large language models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def router_tool(question):\n",
    "  \"\"\"Router Function\"\"\"\n",
    "  if 'self-attention' in question:\n",
    "    return 'vectorstore'\n",
    "  else:\n",
    "    return 'web_search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Router_Agent = Agent(\n",
    "  role='Router',\n",
    "  goal='Route user question to a vectorstore or web search',\n",
    "  backstory=(\n",
    "    \"You are an expert at routing a user question to a vectorstore or web search.\"\n",
    "    \"Use the vectorstore for questions on concept related to Retrieval-Augmented Generation.\"\n",
    "    \"You do not need to be stringent with the keywords in the quesstion related to these topics. Otherwise, use web-search.\"\n",
    "  ),\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retriever_Agent = Agent(\n",
    "role=\"Retriever\",\n",
    "goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
    "backstory=(\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the information present in the retrieved context to answer the question.\"\n",
    "    \"You have to provide a clear concise answer.\"\n",
    "),\n",
    "verbose=True,\n",
    "allow_delegation=False,\n",
    "llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grader_agent =  Agent(\n",
    "  role='Answer Grader',\n",
    "  goal='Filter out erroneous retrievals',\n",
    "  backstory=(\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question.\"\n",
    "    \"If the document contains keywords related to the user question, grade it as relevant.\"\n",
    "    \"It does not need to be a stringent test.You have to make sure that the answer is relevant to the question.\"\n",
    "  ),\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_grader = Agent(\n",
    "    role=\"Hallucination Grader\",\n",
    "    goal=\"Filter out hallucination\",\n",
    "    backstory=(\n",
    "        \"You are a hallucination grader assessing whether an answer is grounded in / supported by a set of facts.\"\n",
    "        \"Make sure you meticulously review the answer and check if the response provided is in alignmnet with the question asked\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_grader = Agent(\n",
    "    role=\"Answer Grader\",\n",
    "    goal=\"Filter out hallucination from the answer.\",\n",
    "    backstory=(\n",
    "        \"You are a grader assessing whether an answer is useful to resolve a question.\"\n",
    "        \"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n",
    "        \"If the answer is relevant generate a clear and concise response.\"\n",
    "        \"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool'\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_task = Task(\n",
    "    description=(\"Analyse the keywords in the question {question}\"\n",
    "    \"Based on the keywords decide whether it is eligible for a vectorstore search or a web search.\"\n",
    "    \"Return a single word 'vectorstore' if it is eligible for vectorstore search.\"\n",
    "    \"Return a single word 'websearch' if it is eligible for web search.\"\n",
    "    \"Do not provide any other premable or explaination.\"\n",
    "    ),\n",
    "    expected_output=(\"Give a binary choice 'websearch' or 'vectorstore' based on the question\"\n",
    "    \"Do not provide any other premable or explaination.\"),\n",
    "    agent=Router_Agent,\n",
    "    tools=[router_tool],\n",
    "    inputs=[\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_task = Task(\n",
    "    description=(\"Based on the response from the router task extract information for the question {question} with the help of the respective tool.\"\n",
    "    \"Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.\"\n",
    "    \"Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\"\n",
    "    ),\n",
    "    expected_output=(\"You should analyse the output of the 'router_task'\"\n",
    "    \"If the response is 'websearch' then use the web_search_tool to retrieve information from the web.\"\n",
    "    \"If the response is 'vectorstore' then use the rag_tool to retrieve information from the vectorstore.\"\n",
    "    \"Return a claer and consise text as response.\"),\n",
    "    agent=Retriever_Agent,\n",
    "    context=[router_task],\n",
    "   #tools=[retriever_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader_task = Task(\n",
    "    description=(\"Based on the response from the retriever task for the quetion {question} evaluate whether the retrieved content is relevant to the question.\"\n",
    "    ),\n",
    "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the document is relevant to the question\"\n",
    "    \"You must answer 'yes' if the response from the 'retriever_task' is in alignment with the question asked.\"\n",
    "    \"You must answer 'no' if the response from the 'retriever_task' is not in alignment with the question asked.\"\n",
    "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
    "    agent=Grader_agent,\n",
    "    context=[retriever_task],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_task = Task(\n",
    "    description=(\"Based on the response from the grader task for the quetion {question} evaluate whether the answer is grounded in / supported by a set of facts.\"),\n",
    "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the answer is sync with the question asked\"\n",
    "    \"Respond 'yes' if the answer is in useful and contains fact about the question asked.\"\n",
    "    \"Respond 'no' if the answer is not useful and does not contains fact about the question asked.\"\n",
    "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
    "    agent=hallucination_grader,\n",
    "    context=[grader_task],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_task = Task(\n",
    "    description=(\"Based on the response from the hallucination task for the quetion {question} evaluate whether the answer is useful to resolve the question.\"\n",
    "    \"If the answer is 'yes' return a clear and concise answer.\"\n",
    "    \"If the answer is 'no' then perform a 'websearch' and return the response\"),\n",
    "    expected_output=(\"Return a clear and concise response if the response from 'hallucination_task' is 'yes'.\"\n",
    "    \"Perform a web search using 'web_search_tool' and return ta clear and concise response only if the response from 'hallucination_task' is 'no'.\"\n",
    "    \"Otherwise respond as 'Sorry! unable to find a valid response'.\"),\n",
    "    context=[hallucination_task],\n",
    "    agent=answer_grader,\n",
    "    #tools=[answer_grader_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 15:07:46,408 - 2608 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "rag_crew = Crew(\n",
    "    agents=[Router_Agent, Retriever_Agent, Grader_agent, hallucination_grader, answer_grader],\n",
    "    tasks=[router_task, retriever_task, grader_task, hallucination_task, answer_task],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyse the keywords in the question Tell me about self-attention mechanism in Transformers?Based on the keywords decide whether it is eligible for a vectorstore search or a web search.Return a single word 'vectorstore' if it is eligible for vectorstore search.Return a single word 'websearch' if it is eligible for web search.Do not provide any other premable or explaination.\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to analyze the user question and determine whether it's suitable for a vectorstore search or a web search. The question is \"Tell me about self-attention mechanism in Transformers?\". The keywords \"self-attention mechanism\" and \"Transformers\" are related to Retrieval-Augmented Generation concepts. Therefore, it is eligible for vectorstore search.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrouter_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function.\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [router_tool]\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to analyze the user question and determine whether it's suitable for a vectorstore search or a web search. The question is \"Tell me about self-attention mechanism in Transformers?\". The keywords \"self-attention mechanism\" and \"Transformers\" are related to Retrieval-Augmented Generation concepts. Therefore, it is eligible for vectorstore search.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrouter_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"question\\\": \\\"Tell me about self-attention mechanism in Transformers?\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function.\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [router_tool]\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "vectorstore\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRetriever\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the router task extract information for the question Tell me about self-attention mechanism in Transformers? with the help of the respective tool.Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\u001b[00m\n",
      "\u001b[91m Error parsing LLM output, agent will retry: I did it wrong. Invalid Format: I missed the 'Action Input:' after 'Action:'. I will do right next, and don't use a tool I have already used.\n",
      "\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "Action 'rag_tool' don't exist, these are the only available Actions:\n",
      "\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRetriever\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrag_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"self-attention mechanism in Transformers\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "I encountered an error: Action 'rag_tool' don't exist, these are the only available Actions:\n",
      "\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of []\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\u001b[91m Error parsing LLM output, agent will retry: I did it wrong. Tried to both perform Action and give a Final Answer at the same time, I must do one or the other\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "inputs ={\"question\":\"Tell me about self-attention mechanism in Transformers?\"}\n",
    "result = rag_crew.kickoff(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The self-attention mechanism in Transformers allows the model to weigh the importance of different parts of the input sequence when processing each part. It enables the model to focus on the most relevant words or tokens in the sequence when encoding a specific word or token.\n",
      "\n",
      "Here's a breakdown of how it works:\n",
      "\n",
      "1.  **Input Transformation:** Each word/token in the input sequence is transformed into three vectors: a Query vector (Q), a Key vector (K), and a Value vector (V). These vectors are learned linear projections of the input embedding.\n",
      "\n",
      "2.  **Attention Weights Calculation:** For each word, the attention weights are calculated by taking the dot product of its Query vector with the Key vectors of all other words in the sequence. This results in a score representing the similarity or relevance between the word and every other word.\n",
      "\n",
      "3.  **Scaling:** The scores are scaled down (typically by the square root of the dimension of the Key vectors) to prevent them from becoming too large, which can lead to unstable training.\n",
      "\n",
      "4.  **Softmax:** A softmax function is applied to the scaled scores to convert them into probabilities. These probabilities represent the attention weights, indicating the importance of each word in relation to the current word.\n",
      "\n",
      "5.  **Weighted Sum:** The Value vectors of all words are multiplied by their corresponding attention weights. These weighted Value vectors are then summed up to produce the final output for the current word. This output is a context-aware representation of the word, taking into account the other words in the sequence.\n",
      "\n",
      "In essence, self-attention allows the model to dynamically adjust its focus to different parts of the input sequence, enabling it to capture long-range dependencies and understand the relationships between words in a more nuanced way. This is a key component of the Transformer architecture and contributes significantly to its success in various NLP tasks.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyse the keywords in the question Tell me about LLMs using web_search?Based on the keywords decide whether it is eligible for a vectorstore search or a web search.Return a single word 'vectorstore' if it is eligible for vectorstore search.Return a single word 'websearch' if it is eligible for web search.Do not provide any other premable or explaination.\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThe question \"Tell me about LLMs\" is a general question about Large Language Models, which falls under the domain of Retrieval-Augmented Generation concepts. Therefore, it is eligible for a vectorstore search.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrouter_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function.\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [router_tool]\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI will try again.\n",
      "Thought: The question \"Tell me about LLMs\" is a general question about Large Language Models, which falls under the domain of Retrieval-Augmented Generation concepts. Therefore, it is eligible for a vectorstore search.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrouter_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"question\\\": \\\"Tell me about LLMs\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function.\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [router_tool]\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI will try again.\n",
      "Thought: The question is \"Tell me about LLMs\". This question is related to Large Language Models, which are a core concept in Retrieval-Augmented Generation. Therefore, it is appropriate to use a vectorstore to answer this question.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrouter_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function.\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [router_tool]\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\u001b[91m \n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI will try again.\n",
      "Thought: The question is about LLMs. This is related to Retrieval-Augmented Generation.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mrouter_tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "I encountered an error while trying to use the tool. This was the error: router_tool() missing 1 required positional argument: 'question'.\n",
      " Tool router_tool accepts these inputs: Tool Name: router_tool\n",
      "Tool Arguments: {}\n",
      "Tool Description: Router Function.\n",
      "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [router_tool]\n",
      "Action Input: the input to the action, dictionary enclosed in curly braces\n",
      "Observation: the result of the action\n",
      "```\n",
      "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now can give a great answer\n",
      "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
      "\n",
      "```\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "vectorstore\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRetriever\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the router task extract information for the question Tell me about LLMs using web_search? with the help of the respective tool.Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRetriever\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "LLMs, or Large Language Models, are sophisticated AI models trained on massive datasets of text and code. They possess the ability to understand and generate human-like text, enabling them to perform a wide range of tasks, including:\n",
      "\n",
      "*   **Text Generation:** Creating various types of content, such as articles, poems, scripts, and code.\n",
      "*   **Translation:** Converting text from one language to another.\n",
      "*   **Question Answering:** Providing answers to questions based on their training data.\n",
      "*   **Summarization:** Condensing large amounts of text into shorter, more concise summaries.\n",
      "*   **Conversational AI:** Powering chatbots and virtual assistants.\n",
      "\n",
      "Key characteristics of LLMs include their large size (in terms of parameters), their ability to learn from vast amounts of data, and their capacity to generalize to new tasks. Prominent examples of LLMs include GPT-3, LaMDA, and BERT.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the retriever task for the quetion Tell me about LLMs using web_search? evaluate whether the retrieved content is relevant to the question.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "yes\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHallucination Grader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the grader task for the quetion Tell me about LLMs using web_search? evaluate whether the answer is grounded in / supported by a set of facts.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHallucination Grader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "yes\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the hallucination task for the quetion Tell me about LLMs using web_search? evaluate whether the answer is useful to resolve the question.If the answer is 'yes' return a clear and concise answer.If the answer is 'no' then perform a 'websearch' and return the response\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Okay.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs ={\"question\":\"Tell me about LLMs using web_search?\"}\n",
    "result = rag_crew.kickoff(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) are a type of artificial intelligence (AI) designed to process and generate human-like language. They are trained on vast amounts of text data and can be used for a variety of tasks such as language translation, text summarization, and chatbots. LLMs are a key technology in the development of natural language processing (NLP) and have many potential applications in fields such as customer service, marketing, and education.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
